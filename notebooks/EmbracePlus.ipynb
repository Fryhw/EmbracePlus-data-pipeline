{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to demonstrate the genericity of our approaches by utilizing a **sample of Embraceplus data** (requested by the Empatica website).\n",
    "\n",
    "Specifically, we will demonstrate the following:\n",
    "- Non-wear detection (and the non-wear detection visulaization)\n",
    "- Skin conductance signal processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from itertools import cycle\n",
    "from pathlib import Path\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from functional import seq\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly_resampler import FigureResampler\n",
    "from plotly_resampler.aggregation import MedDiffGapHandler\n",
    "\n",
    "from code_utils.embraceplus import AvroParser\n",
    "from code_utils.embraceplus.nonwear import embraceplus_wrist_pipeline\n",
    "from code_utils.empatica.scl_processing import process_gsr_pipeline\n",
    "from code_utils.empatica.processing_visualization import plot_gsr_cols\n",
    "from code_utils.path_conf import loc_data_dir\n",
    "\n",
    "USE_PNG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "# NOTE: RAW EmbracePlus data is provided in the form of avro files\n",
    "\n",
    "#avro_paths = list(Path(loc_data_dir).rglob(\"EmbracePlus*/**/*.avro\")) # Test on some files\n",
    "\n",
    "root_path = \"../loc_data/participant_data/\"\n",
    "pattern = os.path.join(root_path, \"2025-04-25\", \"TEST2-3YK3L151MP\", \"raw_data\", \"v6\", \"*.avro\") # Oriented date and user selection version\n",
    "avro_paths = glob.glob(pattern)\n",
    "\n",
    "avros = []\n",
    "for avro_path in avro_paths:\n",
    "    #print(avro_path)\n",
    "    avro_list = AvroParser.parse_avro_file(avro_path)\n",
    "    assert (len(avro_list)) == 1\n",
    "    avros.extend(avro_list)\n",
    "    del avro_list\n",
    "\n",
    "del avro_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the metadata of the first two avro files\n",
    "display(avros[0][\"metadata\"])\n",
    "display(avros[1][\"metadata\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THe metadata is the same, so we can merge the avros\n",
    "merged_avros = AvroParser.merge_avro_data(avros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Demo 1*: on-wrist detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc = merged_avros[\"acc\"].set_index(\"timestamp\")\n",
    "df_eda = merged_avros[\"eda\"].set_index(\"timestamp\")\n",
    "df_tmp = merged_avros[\"tmp\"].set_index(\"timestamp\")\n",
    "df_bvp = merged_avros[\"bvp\"].set_index(\"timestamp\")\n",
    "\n",
    "df_eda = df_eda.fillna(df_eda.mean())\n",
    "df_tmp = df_tmp.fillna(df_tmp.mean())\n",
    "df_acc = df_acc.fillna(df_acc.mean())\n",
    "df_bvp = df_bvp.fillna(df_bvp.mean())\n",
    "\n",
    "df_eda = df_eda.loc[\"2025-04-25\"]\n",
    "df_tmp = df_tmp.loc[\"2025-04-25\"]\n",
    "df_bvp = df_bvp.loc[\"2025-04-25\"]\n",
    "df_acc = df_acc.loc[\"2025-04-25\"]\n",
    "\n",
    "\n",
    "# Traitement avec le pipeline\n",
    "out = embraceplus_wrist_pipeline.process(\n",
    "    [df_eda, df_tmp, df_acc], return_all_series=False, return_df=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_bvp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_bvp\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_bvp' is not defined"
     ]
    }
   ],
   "source": [
    "df_bvp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = FigureResampler(\n",
    "    make_subplots(\n",
    "        rows=5,\n",
    "        cols=1,\n",
    "        shared_xaxes=True,\n",
    "        vertical_spacing=0.06,\n",
    "        subplot_titles=[\n",
    "            \"(i) Skin Conductance\",\n",
    "            \"(ii) Skin Temperature\",\n",
    "            \"(iii) ACC_x-SD (w=1s)\",\n",
    "            \"(iv) Raw ACC\",\n",
    "             \"(v) Bvp\",\n",
    "        ],\n",
    "        specs=[[{\"secondary_y\": True}] for _ in range(5)],\n",
    "    ),\n",
    "    default_n_shown_samples=1000,\n",
    "    show_mean_aggregation_size=False,\n",
    "    resampled_trace_prefix_suffix=(\"\", \"\"),\n",
    ")\n",
    "\n",
    "\n",
    "# ROW 1 -----------------------------------------------------\n",
    "for col in df_eda.columns:\n",
    "    s_c = df_eda[col]\n",
    "    fig.add_trace(go.Scatter(name=col, opacity=0.4), hf_x=s_c.index, hf_y=s_c)\n",
    "\n",
    "for col in [\"EDA_SQI\"]:\n",
    "    s_c = seq(out).filter(lambda x: x.name == col).to_list()[0]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(name=col, opacity=0.8),\n",
    "        hf_x=s_c.index,\n",
    "        hf_y=s_c.astype(float),\n",
    "        secondary_y=True,\n",
    "    )\n",
    "\n",
    "# ROW 2 -----------------------------------------------------\n",
    "for col in df_tmp.columns:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(name=col, opacity=0.4, legend=\"legend2\"),\n",
    "        hf_x=df_tmp[col].index,\n",
    "        hf_y=df_tmp[col],\n",
    "        row=2,\n",
    "        col=1,\n",
    "        limit_to_view=True,\n",
    "    )\n",
    "\n",
    "\n",
    "for col in [\"TMP_SQI\"]:\n",
    "    s_c = seq(out).filter(lambda x: x.name == col).to_list()[0]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(name=col, opacity=0.8, legend=\"legend2\"),\n",
    "        hf_x=s_c.index,\n",
    "        hf_y=s_c.astype(float),\n",
    "        row=2,\n",
    "        col=1,\n",
    "        secondary_y=True,\n",
    "    )\n",
    "\n",
    "# ROW 3 -----------------------------------------------------\n",
    "for col in [\"AI\"]:\n",
    "    s_c = seq(out).filter(lambda x: x.name == col).to_list()[0]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(opacity=0.4, name=\"ACC_x SD\", legend=\"legend3\"),\n",
    "        hf_x=np.ascontiguousarray(s_c.index),\n",
    "        hf_y=np.ascontiguousarray(s_c.values),\n",
    "        row=3,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "\n",
    "for col in [\"AI_SQI\"]:\n",
    "    s_c = seq(out).filter(lambda x: x.name == col).to_list()[0]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(name=\"ACC-SD SQI\", opacity=0.6, line_width=1, legend=\"legend3\"),\n",
    "        hf_x=s_c.index,\n",
    "        hf_y=s_c.astype(float),\n",
    "        secondary_y=True,\n",
    "        row=3,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "\n",
    "# ROW 4 -----------------------------------------------------\n",
    "for col in df_acc.columns:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(name=f\"{col}\", opacity=0.4, legend=\"legend4\"),\n",
    "        hf_x=df_acc[col].index,\n",
    "        hf_y=df_acc[col],\n",
    "        row=4,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "for col in [\"Wrist_SQI\", \"On_Wrist_SQI_smoothened\"][1:]:\n",
    "    s_c = seq(out).filter(lambda x: x.name == col).to_list()[0]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            name=\"Wrist_SQI\", line_color=\"#fd5c63\", line_width=4, legend=\"legend4\"\n",
    "        ),\n",
    "        hf_x=s_c.index,\n",
    "        hf_y=s_c.astype(float),\n",
    "        row=4,\n",
    "        col=1,\n",
    "        secondary_y=True,\n",
    "    )\n",
    "\n",
    "\n",
    "# ROW 5 ----------------------------------------------------------\n",
    "\n",
    "for col in df_bvp.columns:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(name=f\"{col}\", opacity=0.4, legend=\"legend5\"),\n",
    "        hf_x=df_bvp[col].index,\n",
    "        hf_y=df_bvp[col],\n",
    "        row=5,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------- LAYOUT --------------------------------\n",
    "fig.update_layout(template=\"plotly_white\", height=750)\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        **dict(orientation=\"h\", yanchor=\"bottom\", xanchor=\"left\", font_size=19),\n",
    "        **dict(y=1.0, x=0, itemsizing=\"constant\"),\n",
    "    ),\n",
    "    legend2=dict(\n",
    "        **dict(orientation=\"h\", yanchor=\"bottom\", xanchor=\"left\", font_size=19),\n",
    "        **dict(y=0.73, x=0, itemsizing=\"constant\"),\n",
    "    ),\n",
    "    legend3=dict(\n",
    "        **dict(orientation=\"h\", yanchor=\"bottom\", xanchor=\"left\", font_size=19),\n",
    "        **dict(y=0.47, x=0, itemsizing=\"constant\"),\n",
    "    ),\n",
    "    legend4=dict(\n",
    "        **dict(orientation=\"h\", yanchor=\"bottom\", xanchor=\"left\", font_size=19),\n",
    "        **dict(y=0.21, x=0, itemsizing=\"constant\"),\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.update_yaxes(title_text=\"μS\", row=1, col=1, title_font_size=20)\n",
    "fig.update_yaxes(title_text=\"°C\", row=2, col=1, title_font_size=20)\n",
    "fig.update_yaxes(title_text=\"g\", row=3, col=1, title_font_size=20)\n",
    "fig.update_yaxes(title_text=\"g\", row=4, col=1, title_font_size=20)\n",
    "fig.update_yaxes(title_text=\"BVP (a.u.)\", row=5, col=1, title_font_size=20)\n",
    "\n",
    "\n",
    "fig.update_layout(margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig.update_annotations(font_size=24)\n",
    "# update tick sizes\n",
    "fig.update_xaxes(tickfont_size=18)\n",
    "fig.update_yaxes(tickfont_size=18)\n",
    "\n",
    "# do not show seconds on the y-axis\n",
    "fig.update_yaxes(visible=False, secondary_y=True, range=[-.05, 1.05])\n",
    "\n",
    "fig.show_dash(mode=\"inline\", port=8002)\n",
    "if USE_PNG:\n",
    "    fig.show(renderer=\"png\", width=1650, height=750)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**notes**:\n",
    "- As outline in the [embraceplus/nonwear.py](../code_utils/embraceplus/nonwear.py), minimal code was adapted w.r.t. the original Empatica E4 code.\n",
    "- The above visualization is a copy of the original Empatica E4 visualization\n",
    "\n",
    "This hints a genericity of our E4 approach towards the Embraceplus device.\n",
    "\n",
    "\n",
    "Remark that, as we do not have a lot of EmbracePlus data, it is hard to make statements about the performance of the non-wear detection and its current parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_16524\\1613382179.py:1: FutureWarning: last is deprecated and will be removed in a future version. Please create a mask and filter using `.loc` instead\n",
      "  eda_slc = merged_avros[\"eda\"].set_index(\"timestamp\").last('12h')\n"
     ]
    }
   ],
   "source": [
    "eda_slc = merged_avros[\"eda\"].set_index(\"timestamp\").last('12h')\n",
    "out = process_gsr_pipeline(eda_slc, use_scr_pipeline=False, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDA_SQI------------------------------\n",
      "EDA_SQI_smoothend------------------------------\n",
      "EDA_delta_SQI------------------------------\n",
      "EDA_lf_1Hz------------------------------\n",
      "EDA_lf_cleaned------------------------------\n",
      "EDA_lost_SQI------------------------------\n",
      "EDA_noise_SQI------------------------------\n",
      "EDA_slope_SQI------------------------------\n",
      "noise------------------------------\n",
      "noise_mean_2s------------------------------\n",
      "raw_cleaned------------------------------\n",
      "raw_cleaned_duration_filter------------------------------\n",
      "slope------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"668\"\n",
       "            src=\"http://127.0.0.1:8002/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1ae584885c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eda_cleaned = out[\"EDA_lf_cleaned\"]\n",
    "\n",
    "fig = FigureResampler(\n",
    "    make_subplots(\n",
    "        rows=2,\n",
    "        cols=1,\n",
    "        shared_xaxes=True,\n",
    "        specs=[[{\"secondary_y\": True}], [{\"secondary_y\": True}]],\n",
    "        vertical_spacing=0.07,\n",
    "        # colorway=px.colors.qualitative.Plotly,\n",
    "    ),\n",
    "    show_mean_aggregation_size=False,\n",
    "    resampled_trace_prefix_suffix=(\"\", \"\"),\n",
    ")\n",
    "\n",
    "# ROW 1 -----------------------------------------------------\n",
    "fig.add_trace(\n",
    "    go.Scatter(name=\"EDA (Raw)\", line_color=\"dimgrey\", legend=\"legend1\"),\n",
    "    **{\"hf_x\": eda_slc.index, \"hf_y\": eda_slc[\"EDA\"], \"row\": 1, \"col\": 1},\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(name=\"EDA (processed)\", line_color=\"orange\", legend=\"legend1\"),\n",
    "    **{\"hf_x\": eda_cleaned.index, \"hf_y\": eda_cleaned, \"row\": 1, \"col\": 1},\n",
    ")\n",
    "\n",
    "\n",
    "# ROW 2 -----------------------------------------------------\n",
    "plot_gsr_cols(\n",
    "    fig,\n",
    "    out,\n",
    "    row_idx=1,\n",
    "    add_skip_cols=[\"EDA_delta_SQI\", \"noise\", \"EDA_lf_cleaned\"],\n",
    "    palette=cycle(px.colors.qualitative.Plotly[2:]),\n",
    ")\n",
    "\n",
    "\n",
    "# Set the layout\n",
    "fig.update_layout(\n",
    "    template=\"plotly_white\",\n",
    "    height=650,\n",
    "    legend1=dict(\n",
    "        y=1.04,\n",
    "        bgcolor=\"rgba(0,0,0,0)\",\n",
    "        orientation=\"h\",\n",
    "        font_size=15,\n",
    "        itemsizing=\"constant\",\n",
    "    ),\n",
    "    legend2=dict(\n",
    "        y=0.52,\n",
    "        bgcolor=\"rgba(0,0,0,0)\",\n",
    "        orientation=\"h\",\n",
    "        font_size=15,\n",
    "        itemsizing=\"constant\",\n",
    "    ),\n",
    "    # update the font_size of the axis ticks labels\n",
    "    font=dict(size=15),\n",
    ")\n",
    "\n",
    "# hide the tick-labels of the secondary y-axes\n",
    "fig.update_yaxes(title_text=\"µS\", row=1, col=1, titlefont_size=18)\n",
    "fig.update_yaxes(visible=False, showticklabels=False, row=1, col=1, secondary_y=True)\n",
    "fig.update_yaxes(\n",
    "    visible=False, showticklabels=False, row=2, col=1, range=[-2, 1.1], secondary_y=True\n",
    ")\n",
    "#     fig.show(renderer=\"png\", width=1400, height=750)\n",
    "fig.show_dash(port=8002, mode=\"inline\")\n",
    "\n",
    "if USE_PNG:\n",
    "    fig.show(renderer=\"png\", width=1400, height=750)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**notes**:\n",
    "\n",
    "- This code is a straight copy from the Empatica E4 code, again hinting at the genericity of our approach.\n",
    "\n",
    "The same remark as above applies here: we cannot make statements about the performance of the signal processing and its current parameters due to the lack of data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
